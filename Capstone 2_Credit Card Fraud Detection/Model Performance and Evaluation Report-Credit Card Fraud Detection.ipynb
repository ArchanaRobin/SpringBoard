{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91a6ae4b",
   "metadata": {},
   "source": [
    "\n",
    "### Credit Card Fraud Detection \n",
    "\n",
    "## Model Performance and Evaluation Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f948cefd",
   "metadata": {},
   "source": [
    "#### List of items:\n",
    "\n",
    "Introduction to Credit Card Fraud Detection\n",
    "\n",
    "Model Exploration and Preprocessing\n",
    "\n",
    "Model Performance and Evaluation\n",
    "\n",
    "Conclusion\n",
    "\n",
    "Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4f4653",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "One major challenge credit card companies face year after year is to identify fraudulent transactions. \n",
    "\n",
    "Many controls have been implemented to address this issue. However, most solutions add additional burdens to the customers.\n",
    "\n",
    "We decided to address this complex problem by implementing machine learning models to identify fraudulent transactions based on usersâ€™ behavior. \n",
    "\n",
    "We present a synthetic dataset generated using the simulator called PaySim as an approach to such a problem. The dataset is highly imbalanced. Here We applied Various algorithms. In this case 1 step is 1 hour of time. Total steps 744 (30 days simulation)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7282fc",
   "metadata": {},
   "source": [
    "### Model Exploration and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eba35eb",
   "metadata": {},
   "source": [
    " #### Performed procedures:\n",
    " \n",
    "  - Data Wrangling and Exploration \n",
    "    - Reading, understanding, cleaning, and visualising the data\n",
    "    \n",
    "    \n",
    " - Preprocessing \n",
    "    - Preparing the data for modeling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ff7eb5",
   "metadata": {},
   "source": [
    "#### Exploratory Data Analysis Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075b8ecb",
   "metadata": {},
   "source": [
    "  - There are 8213 fraud transactions reported.\n",
    "    - There are 4116 Fraud transaction in CASH_OUT and 4097 in TRANSFER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61852eae",
   "metadata": {},
   "source": [
    "![](img1.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379eef9f",
   "metadata": {},
   "source": [
    " - The maximum amount of Fraud transaction is 10,000,000.\n",
    "     - The The main fraud transaction catogories are TRANSFER and CASH_OUT."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f00549",
   "metadata": {},
   "source": [
    "![](img2.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eced909",
   "metadata": {},
   "source": [
    "  - Most of the fraud transactions are happening after 12:00am to 8:00am.\n",
    "    -  The data is stable during the banking hours."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6371c05",
   "metadata": {},
   "source": [
    "![](img3..png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef51aacc",
   "metadata": {},
   "source": [
    " - Fraudulent transaction is almost consistent across days"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ec5a6f",
   "metadata": {},
   "source": [
    "![](img4.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e754a8",
   "metadata": {},
   "source": [
    "-  In Normal hours, Customer to Customer transactions are greater than Customer to Merchant transactions.\n",
    "     - But Customer to Merchant transactions are happening off-peak hours"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400020d1",
   "metadata": {},
   "source": [
    "![](img5.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442678c2",
   "metadata": {},
   "source": [
    "Before the model development, we split the data into train and test samples. \n",
    "Here we used \"Isfraid\" feature as our dependent variable for testing purpose and the remaining are used as independent variable for training purpose.\n",
    "He we used 20% of the data to test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860e985e",
   "metadata": {},
   "source": [
    "### Model prediction and Evaluation\n",
    "\n",
    "Since the data for this project is very imbalanced, the number of cases of Fraud transactions are very low in comparison to number of cases of Valid transactions. \n",
    "We have achieved 99% accuracy at the end of the training and testing.\n",
    "we have used  different type of matric to find the performance of the algorithm.\n",
    "\n",
    "In heavily imbalanced data Accuracy is not a good measure for evaluating the model.\n",
    "\n",
    " - Outlier technique:\n",
    "    - We are not performing any outliers transformtion technique for this dataset. Usually Hyperparameter tuning can overcome the skewed situation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0405f3",
   "metadata": {},
   "source": [
    "#### Applied Machine Learning Algorithms\n",
    "\n",
    " - Random ForestClassifier\n",
    " \n",
    " - XgBoost\n",
    " \n",
    " - Logistic Regression\n",
    " \n",
    " - Decision Tree\n",
    "\n",
    "\n",
    " \n",
    " #### Used Matrics:\n",
    "\n",
    " - Accuracy\n",
    " \n",
    " - Precision\n",
    " \n",
    " - F1-Score\n",
    " \n",
    " - Recall\n",
    " \n",
    " - AUC/ROC Curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f196f134",
   "metadata": {},
   "source": [
    "In our data set we have measured the ROC-AUC score for fair evaluation of the model. The ROC curve is used to understand the strength of the model by evaluating the performance of the model at all the classification thresholds.\n",
    "The default threshold of 0.5 is not always the ideal threshold to find the best classification label of the test point.  After determining the optimal threshold, we calculated the F1 score of the classifier to measure the precision and recall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762b8273",
   "metadata": {},
   "source": [
    " **<font color='Red'> Random Forest Algorithm prediction: </font>**\n",
    "    \n",
    " - <font color='blue'>  Accuracy Score is not a good metric for imbalanced data. So, here we performed manual hyperparameter tuning, F-Beta store, ROC-AUC score, and precision score to get  better performance.\n",
    "\n",
    " - <font color='blue'>  The precision score 99.87%,  ROC curve - 99.72%, and F1 score gives us 99.99%. \n",
    "  \n",
    "  \n",
    " - <font color='blue'> Here we found type I error(False Positive) with 12 fraud values which predicted not fraud. So we found the precision score. \n",
    "\n",
    "  \n",
    " - <font color='blue'> As we got good accuracy with Manual method, RandomizedSearchCV / GridsearchCV is not performed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b886b742",
   "metadata": {},
   "source": [
    " **<font color='Red'> XgBoost Classifier Algorithm prediction: </font>**\n",
    "        \n",
    "  - <font color='blue'>  Accuracy Score is not a good metric for imbalanced data. So, here we performed hyperparameter tuning, F-Beta store, ROC-AUC score, and precision score to get  better performance.\n",
    "\n",
    " - <font color='blue'> Here we found type I error(False Positive) with 10 fraud values which predicted not fraud. So we found the precision score. \n",
    "\n",
    "    \n",
    " - <font color='blue'>  The precision score  is 100%, ROC curve - 99.83%, and F1 score gives us 99.99%\n",
    "   \n",
    "  \n",
    " - <font color='blue'> Here we have performed GridsearchCV for the best accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1ed2a9",
   "metadata": {},
   "source": [
    "**<font color='Red'> Logistic Regression Algorithm prediction: </font>**\n",
    "        \n",
    " - <font color='blue'>  Accuracy Score is not a good metric for imbalanced data. So, here we performed regularization parameter C, F-Beta store, ROC-AUC score, and precision score to get  better performance.      \n",
    "        \n",
    " - <font color='blue'> - Used the C value in the procedure and train a Logistic Regression on the training data\n",
    "\n",
    " - <font color='blue'>  Here it is clear that the precision score gives us  46.88%. ROC curve - 94.28% and F1 score gives us 99.68%\n",
    "  \n",
    "  \n",
    " - <font color='blue'> Here we found type I error(False Positive) with 935 fraud values which predicted not fraud. So we found the precision score. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfb3f1e",
   "metadata": {},
   "source": [
    " **<font color='Red'> Decision Tree Gini mode Algorithm prediction: </font>**\n",
    " \n",
    "        \n",
    "  - <font color='blue'>  Accuracy Score is not a good metric for imbalanced data. So, here we performed Gini model tuning, F-Beta store, ROC-AUC score, and precision score to get  better performance.    \n",
    " \n",
    "    \n",
    " - <font color='blue'> Here we found type I error(False Positive) with 541 fraud values which predicted not fraud. So we found the precision score. \n",
    "\n",
    "\n",
    "  - <font color='blue'>  Here it is clear that the precision score gives us  98.72%. ROC curve - 98.07% and F1 score gives us 99.89%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838401eb",
   "metadata": {},
   "source": [
    "**<font color='Red'> Decision Tree Entropy model Algorithm prediction: </font>**\n",
    " \n",
    " \n",
    " - <font color='blue'>  Accuracy Score is not a good metric for imbalanced data. So, here we performed Entropy model tuning, F-Beta store, ROC-AUC score, and precision score to get  better performance.\n",
    "    \n",
    "    \n",
    " - <font color='blue'> Here we found type I error(False Positive) with 15 fraud values which predicted not fraud. So we found the precision score. \n",
    " \n",
    "    \n",
    " - <font color='blue'>  Here it is clear that the precision score gives us  99.75%. ROC curve - 99.88% and F1 score gives us 99.99%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13d16d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model Comparison: Put it all "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2653c4",
   "metadata": {},
   "source": [
    "![](img9.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e141ec",
   "metadata": {},
   "source": [
    " In al the five models XgBoost performs well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b81a4e5",
   "metadata": {},
   "source": [
    "#### **<font color='blue'> 1: ROC-AUC score model comparison </font>**\n",
    "\n",
    "In ROC-AUC score XgBoost performs very well. Also, Random Forest and Entropy model performing with a good score. A small variation in the score makes huge loss to the bank. \n",
    "But in imbalanced data we choose F1 Score and precision score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4237ab",
   "metadata": {},
   "source": [
    "![](img6.png \"ROC-AUC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fd83fd",
   "metadata": {},
   "source": [
    " **<font color='blue'> 2: Precision score model comparison </font>**\n",
    "\n",
    "In Precision Score XgBoost performs very well. Also, Random Forest and Entropy model performing with a good score.\n",
    "In imbalanced data Precision Score and F1 score are considered as a good method. Precision can reduce the Type I error called False Positive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1af586",
   "metadata": {},
   "source": [
    "![](img7.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d169d81",
   "metadata": {},
   "source": [
    "**<font color='blue'> 3: F1_score model comparison </font>**\n",
    "In imbalanced data F1_score  is considered as a good method. Here along with XgBoost algorithm, we see Random Forest and Entropy model are also performs very well. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b31891a",
   "metadata": {},
   "source": [
    "![](img8.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022b78b7",
   "metadata": {},
   "source": [
    "### Model Performance and Evaluation Summary:\n",
    "    \n",
    "- XgBoost,  Decision Tree Entropy model, and Random Forest are performing well and gives us the best estimation.\n",
    "   - The best model is XgBoost classification Algorithm with 99.99% performance.\n",
    "   \n",
    "   \n",
    "- Here the matrics F1 score and Precision score gives us the the best value.   \n",
    "   \n",
    "\n",
    "- We have performed the  hyperparameter tuning techniques to handle the quantitative variables in a better manner.\n",
    "\n",
    "\n",
    "- Performed model tuning and selected the regularization parameter 'C' in Logistic Regression classification algorithm.\n",
    "\n",
    "\n",
    "-  In Decision Tree Entropy model performed well\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d183c7",
   "metadata": {},
   "source": [
    "#### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e700770e",
   "metadata": {},
   "source": [
    " This data is highly imbalanced, so the accuracy may not be the correct measure for this particular case\n",
    "\n",
    "It is very important to identify which are fraudulent transactions accurately than the non-fraudulent.\n",
    "Here we have chosen an appropriate evaluation metric which reflects this business goal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23dc1b4",
   "metadata": {},
   "source": [
    "#### References:\n",
    "    Kaggle, Google articles, github"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
